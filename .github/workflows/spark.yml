name: Spark Data Processing

# Trigger the workflow on push or pull requests to the main branch
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  data_processing:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout the repository
      uses: actions/checkout@v2
    
    # Set up Java (required for Spark)
    - name: Set up Java
      uses: actions/setup-java@v2
      with:
        java-version: '21'
        distribution: 'temurin'
    
    # Install Python dependencies
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    # Install Spark
    - name: Install Spark
      run: |
        curl -O https://archive.apache.org/dist/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz
        tar xvf spark-3.5.3-bin-hadoop3.tgz
        mv spark-3.5.3-bin-hadoop3 /usr/local/spark
        echo "SPARK_HOME=/usr/local/spark" >> $GITHUB_ENV
        echo "PATH=$SPARK_HOME/bin:$PATH" >> $GITHUB_ENV
    
    # Run Spark data processing script
    - name: Run Spark Data Processing
      run: |
        python src/data_processing.py

    # Optionally, you can add steps to save the processed data
  #  - name: Upload processed data
  #    uses: actions/upload-artifact@v2
  #    with:
  #      name: processed_data
  #      path: data/processed_people.csv
